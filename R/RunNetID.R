#' @title Run NetID model
#'
#' @description This function is for generating the weighted gene regulatory network (GRN). NetID first sample the cells on the PCA space to make sure the sampled cell could cover the whole manifold. Then aggregate the neighbourhoods around each sampled cells on pruned KNN graph. And in the end run GENIE3 algorithm on the aggregated gene expression profile. The sampling and rational aggregation would make cells denoise and maintain the major variation, and speed up the GRN generating process.
#'
#' @param sce
#' A SingleCellExperiment object need to contain the "count" assay,
#' if it contains the "spliced" and "unspliced" assay, the NetID would run on "spliced" assay
#'
#' @param min_counts
#' minimum detected counts for genes, the genes which has counts > min_counts would be preserved
#' Default: 10
#'
#' @param varID_res
#' input if user already have varID object in the experiment, otherwise need to run pruneKnn algorithm
#' Default: NULL
#'
#' @param knn
#' number of nearest neighbourhoods
#' Default: 30
#'
#' @param regulators
#' a gene list contains the feature names of regulators
#'
#' @param targets
#' a gene list contains the feature names of targets
#'
#' @param netID_params
#' a list object could manually set the parameter for the core algorithm of netID
#' see the details of parameters through ?check_netID_params
#'
#' @param velo
#' if use the fate probability inferred results from RNA velocity based method (cellrank), make sure you have run FateDynamic function
#' before you want to set this parameter = True
#' Default: FALSE
#'
#' @param dynamicInfer
#' if use the fate probability inferred results, make sure you have run FateDynamic function before you want to set this parameter = TRUE
#' Default: FALSE
#'
#' @param maxState
#' NetID would assign the cells to a cell fate (lineage) though clustering the cells according to the fate probability. Internally, NetID
#' would use Gaussain Mixture Model, and it would use BIC to choose optimal number of clusters. User need to set the maximum number of clusters.
#' Default: 5
#'
#' @param cut_off
#' Each cluster would assign to a cell fate through comparing the fate probability fold change (e.g. cell fate A vs. others), a cell fate with
#' fold change > cut_off would be assigned to the corresponding cluster
#' Default: 2
#'
#' @param unique_assign
#' if uniquely assign the cell fate to each cluster
#' Default: FALSE
#'
#' @param restart
#' RunNetID would automatically run the pruneKnn if it couldn't find the VarID_res.rds in the working directory. if VarID_res.rds already have
#' and user still want to re-run the pruneKnn, set the restart = TRUE
#' Default: FALSE
#'
#' @param work_dir
#' user could specific the working directory through input the address, and the varID object (pruneKnn) would be saved in this directory.
#' Otherwise the local working directory would be used (getwd())
#' Default: NULL
#'
#' @param no_cores
#' The number of cores would be used. Default: 4
#'
#'
#' @return a list contains following objects
#' @param fate_prob
#' cell fate probability matrix learned by palantir, only be saved when dynamicInfer = TRUE
#'
#' @param LineageClass
#' the assigment of lineage type to each cell. The palantir fate probability matrix is used when perform assignment
#'
#' @param fate_prob_velo
#' cell fate probability matrix learned by palantir, only be saved when dynamicInfer = TRUE
#'
#' @param LineageClass_velo
#' the assigment of lineage type to each cell. The cellrank fate probability matrix is used when perform assignment
#'
#' @param pseudotime
#' the pseudotime for each cell. pseudotime is learned by palantir
#'
#' @param velocity_pseudotime
#' the pseudotime for each cell. pseudotime is learned by RNA velocity (scVelo)
#'
#' @param GEP
#' NetID inferred aggregated profile on sampling dataset, user could manually choose their GRN inference method and run on this expression profile
#'
#' @param velo_m and velo_m_aggregate
#' the velocity matrix
#'
#' @param skeleton
#' a gene regulatory network skeleton (a binary matrix with 1 indicate have regulation)
#'
#' @param varID_res
#' a varID object generated by pruneKnn
#'
#'
#' @examples
#' \dontrun{
#' dyn.out <- RunNetID(sce,regulators = TF, targets = TF,netID_params = list(normalize=FALSE,n_cell = 5000),velo=FALSE,dynamicInfer = FALSE)
#' }
#'
#' @export
#'

RunNetID <- function(sce,min_counts = 10,varID_res=NULL, knn = 30, regulators = NULL, targets = NULL,netID_params = list(), velo=TRUE,dynamicInfer=TRUE,maxState = 5,cut_off = 2,work_dir = NULL){
  if(!is.null(work_dir)){setwd(work_dir)}
  suppressPackageStartupMessages(require("mclust"))
  suppressPackageStartupMessages(require("GENIE3"))

  env = environment()
  netID_params <- .check_netID_params(netID_params)
  list2env(netID_params,env)

  sce <- sce[,colSums(assays(sce)$spliced)>0]
  X <- assays(sce)$spliced
  X <- X[!duplicated(rownames(X)),]
  X <- X[,colSums(X)>0]
  g <- rownames(X)[rowSums(X)>min_counts]

  if(dynamicInfer){
    sc <- reticulate::import('scanpy', convert = FALSE)
    adata_exp <- sc$read_h5ad("./output/FateRes.h5ad")
    if(velo){
      adata_velo <- sc$read_h5ad("./output_velo/FateRes.h5ad")
      velo_m <- t(py_to_r(adata_velo$layers["velocity"]))
      rownames(velo_m) <- rownames(py_to_r(adata_velo$var))
      colnames(velo_m) <- rownames(py_to_r(adata_velo$obs))
    }

    GEP <- t(py_to_r(adata_exp$X))
    rownames(GEP) <- rownames(py_to_r(adata_exp$var))
    colnames(GEP) <- rownames(py_to_r(adata_exp$obs))
    g <- rownames(GEP)
  }

  # Build GRN
  X <- as.matrix(X)
  if(is.null(varID_res)){
    if(length(intersect(list.files(getwd()),"varID_res.rds")) == 1){
      writeLines("Find VarID object at local dictionary, Read VarID object...")
      varID_res <- readRDS("varID_res.rds")
    }else{
      writeLines("Build VarID object...")
      varID_res   <- pruneKnn(X[g,],knn=as.numeric(knn),no_cores=4, pca.scale = TRUE, FSelect = TRUE)
      saveRDS(varID_res,file="varID_res.rds")
    }
  }
  regulators <- intersect(regulators,g);targets <- intersect(targets,g)

  writeLines("Using NetID to perform skeleton estimation...")
  skeleton <- RunNetID2(spliced = X[g,],varID_obj = varID_res,var=var,sampled_cells = sampled_cells, sketch.method = sketch.method,n_cell = n_cell,ndim = ndim,regulators = regulators,targets = targets,Threshold_Num = Threshold_Num,normalize = normalize,prior_net = prior_net)

  if(dynamicInfer){
    ##########################
    ## extract phase information from velocity vector
    ## load normalized GEP
    # load fate probability
    fate_prob <- py_to_r(adata_exp$obs)
    ID <- colnames(fate_prob)[-ncol(fate_prob)]
    barcode <- rownames(fate_prob)
    fate_prob <- as.matrix(fate_prob[,-ncol(fate_prob)])
    rownames(fate_prob) <- barcode
    colnames(fate_prob) <- ID

    if(velo){
      fate_prob_velo <- py_to_r(adata_velo$obs)
      ID <- colnames(fate_prob_velo)[-ncol(fate_prob_velo)]
      barcode <- rownames(fate_prob_velo)
      fate_prob_velo <- as.matrix(fate_prob_velo[,-ncol(fate_prob_velo)])
      rownames(fate_prob_velo) <- barcode
      colnames(fate_prob_velo) <- ID

      ### generate aggregate velo_m
      velo_m_aggre <- apply(skeleton$y.final,2,function(x){  f <- colnames(velo_m) %in% rownames(skeleton$y.final)[ x > 0]; rowMeans(as.matrix(velo_m[,f]))} )
      colnames(velo_m_aggre) <- colnames(skeleton$y.final)
      rownames(velo_m_aggre) <- rownames(velo_m)
    }

    cat("Classify lineage for palantir fate prob...\n")
    if(ncol(fate_prob)==1){
      LineageClass <- LineageClassifer(fate_prob,maxState = maxState, cut_off = cut_off)
    }else{
      LineageClass <- LineageClassifer(fate_prob,maxState = maxState, cut_off = cut_off)
    }

    if(velo){
      cat("Classify lineage for cellrank fate prob...\n")
      if(ncol(fate_prob_velo)==1){
        LineageClass_velo <- list()
        LineageClass_velo[[colnames(fate_prob_velo)]] <- rownames(fate_prob_velo)
      }else{
        LineageClass_velo <- LineageClassifer(fate_prob_velo,maxState = maxState)
      }
    }

    ########
    pseudotime <- py_to_r(adata_exp$obs)$pseudotime
    names(pseudotime) <- rownames(py_to_r(adata_exp$obs))

    if(velo){
      velocity_pseudotime <- py_to_r(adata_velo$obs)$velocity_pseudotime
      names(velocity_pseudotime) <- rownames(py_to_r(adata_velo$obs))
    }
  }
  ########
  writeLines("Done...")
  res <- list()
  if(dynamicInfer){
    res$fate_prob = fate_prob;res$LineageClass = LineageClass
    if(velo){res$fate_prob_velo = fate_prob_velo;res$LineageClass_velo = LineageClass_velo}
    res$pseudotime <- pseudotime
    if(velo) res$velocity_pseudotime <- velocity_pseudotime
    if(velo) res$velo_m <- velo_m
    if(velo) res$velo_m_aggre <- velo_m_aggre
    res$GEP <- GEP
  }
  res$skeleton <- skeleton
  res$varID_res <- varID_res
  return(res)
}


RunNetID2 <- function(spliced, varID_obj,var=FALSE, sampled_cells=NULL,sketch.method = "SeuratSketching",ndim = 50, n_cell = 500, Threshold_Num = 5, regulators = NULL, targets = NULL,normalize=TRUE,prior_net = NULL){
  suppressPackageStartupMessages(require(Matrix))
  suppressPackageStartupMessages(require(reticulate))
  suppressPackageStartupMessages(require(rsvd))
  suppressPackageStartupMessages(require(Seurat))
  suppressPackageStartupMessages(require(GENIE3))

  ### perform geosketch sampling on expression profile
  if(is.null(sampled_cells)){
    exp.m = spliced
    sketch.indices = Sketching(exp.m = exp.m, varID_obj = varID_obj, var = var,n_cell = n_cell, sketch.method = sketch.method, ndim = ndim)
  }

  pvalue <- 0.01
  if(is.null(sampled_cells)){id <- sampled_cells <- unlist(sketch.indices)}else{
    id <- sampled_cells}

  x  <- t(varID_obj$NN)[id,]
  y  <- Matrix(rep(0,ncol(varID_obj$NN)*length(id)), ncol=ncol(varID_obj$NN))
  rownames(y) <- rownames(x)
  colnames(y) <- colnames(varID_obj$NN)

  writeLines("prune sampled neighbourhoods according to q-value...")
  for ( i in rownames(y) ){
    p <- varID_obj$pvM[,i]
    p[p < pvalue] <- 0
    y[i,varID_obj$NN[,i]] <- c(1,p)
  }
  ## pruned p-value matrix. p-values of pruned neighbours are set to 0.
  y <- as.matrix( t(y) )
  y.prune <- y
  y.prune[y.prune!=0] <- 1

  pvalue <- 0
  x  <- t(varID_obj$NN)[id,]
  y  <- Matrix(rep(0,ncol(varID_obj$NN)*length(id)), ncol=ncol(varID_obj$NN))
  rownames(y) <- rownames(x)
  colnames(y) <- colnames(varID_obj$NN)

  writeLines("assign weight for edges using p-value...")
  for ( i in rownames(y) ){
    p <- varID_obj$pvM.raw[,i]
    y[i,varID_obj$NN[,i]] <- c(1,p)
  }

  y <- as.matrix( t(y) )
  y.unprune <- y;rm(y);gc()

  y.weighted <- y.unprune * y.prune # a weighted and pruned cell-cell graph

  cs <- rowSums(y.weighted)
  f <- cs > 0
  y.weighted <- y.weighted[f,]

  count <- apply(y.weighted,2,function(x){sum(x!=0)})
  y.final <- matrix(0,nrow=nrow(y.weighted),ncol=ncol(y.weighted))
  colnames(y.final) <- colnames(y.weighted)
  rownames(y.final) <- rownames(y.weighted)
  id <- rownames(y.weighted)[rownames(y.weighted) %in% colnames(y.weighted) == FALSE]
  for(i in id){
    vec <- which(y.weighted[i,] == max(y.weighted[i,]))
    vec_count <- count[vec]
    y.final[i,vec[which(vec_count == min(vec_count))]] <- 1
  }

  y.final[colnames(y.final),colnames(y.final)] <- diag(ncol(y.final))
  count <- function(x) { sum(x!=0)}
  #effectSize[[o]] <- apply(y.final,2,count)
  y.final <- y.final[,apply(y.final,2,count)>Threshold_Num]

  #####################################
  #Generate NetID expression profile
  ks.final <- apply(y.final,2,function(x){  f <- colnames(spliced) %in% rownames(y.final)[ x > 0]; rowMeans(as.matrix(spliced[,f]))} )
  colnames(ks.final) <- colnames(y.final)
  rownames(ks.final) <- rownames(spliced)
  g <- unique(c(targets,regulators))
  ks.final <- ks.final[g,]
  if(normalize){s <- colnames(ks.final);
  g <- rownames(ks.final);
  ks.final <- ks.final %*% diag(10^6/colSums(ks.final));
  colnames(ks.final) <- s
  rownames(ks.final) <- g
  }
  #########################################
  writeLines(paste("aggregated matrix: the number of genes:",nrow(ks.final),"; the number of samples:",ncol(ks.final),sep=""))

  g_c <- GENIE3(log2(ks.final+1),nCores=12,verbose=TRUE,nTrees=500,regulators = regulators, targets = targets)


  ### filtering the network according to the weight
  g_c_raw <- g_c
  library(Matrix)
  g_c[g_c<0.001] <- 0
  g_count <- g_c
  g_count[g_count!=0] <- 1
  rank_n <- apply(as.matrix(rowSums(g_count)),1,function(x){min(x,50)})
  for(i in 1:nrow(g_c)){
    g_count[i,][order(g_c[i,],decreasing=TRUE)[1:rank_n[i]]] <- 2
  }
  g_count[g_count!=0] = g_count[g_count!=0] - 1

  ### if directed = TRUE, means row is regulators, column is targets, the direction is determined, we would
  ### have a directed network

  ### if directed = FALSE, means row and column is the same, we would have a undirected network


  if(!is.null(prior_net)){
    g_net = prior_net + g_count
    g_net[g_net!=0] <- g_net[g_net!=0] - 1
  }else{
    g_net = g_count
  }


  ### return the results
  res <- list(skeleton = g_net,g_c = g_c, GENIE3_net = g_c_raw,metaExp = ks.final,metaCells = sampled_cells,y.final = y.final)
  return(res)
}

LineageClassifer <- function(fate_prob,cut_off=2,maxState = 5, diffvar=TRUE, unique_assign = FALSE){
    sampleID <- rownames(fate_prob)
	cellfate <- colnames(fate_prob)
	#fate_prob <- fate_prob %*% diag(1/colMeans(fate_prob))
	#fate_prob <- diag(1/rowSums(fate_prob)) %*% fate_prob
	rownames(fate_prob) <- sampleID
	colnames(fate_prob) <- cellfate
	fateprob.v <- log2(1.000001+ fate_prob / (1.000001 - fate_prob))
	if(diffvar == TRUE){
		## default assumes different variance for clusters
		mcl.o <- Mclust(fateprob.v, G = maxState)
	}
	else {
		mcl.o <- Mclust(fateprob.v, G = maxState, modelNames = c("E"))
	}
	mu.v <- mcl.o$param$mean
    for(i in 1:nrow(mu.v)){
		if(nrow(mu.v) == 2){
		  mu.v[i,] <- mu.v[i,] / mcl.o$param$mean[-i,]
		}else{
		  mu.v[i,] <- mu.v[i,] / colMeans(mcl.o$param$mean[-i,])
		}
	}
	colnames(mu.v) <- paste0("cluster",1:ncol(mu.v))
	class <- mcl.o$classification
	class <- paste0("cluster",class)
	print(mu.v)
	if(unique_assign){
	writeLines("Unique assign cell state into a specific lineage...")
	label <- NULL
	for(i in 1:ncol(mu.v)){
	  if(max(mu.v[,i])>cut_off){
	     label <- c(label, rownames(mu.v)[which.max(mu.v[,i])])
	  }else{
	    label <- c(label,"uncertain")
	  }
	}
	lineage_list <- list()
	drop_fate <- NULL
	for(i in 1:nrow(mu.v)){
	  lineage_list[[i]] <- colnames(mu.v)[which(label %in% c("uncertain",rownames(mu.v)[i]))]
	  lineage_list[[i]] <- rownames(fate_prob)[which(class %in% lineage_list[[i]])]
	  if(length(lineage_list[[i]])==0) drop_fate <- c(drop_fate,i)
	}
	names(lineage_list) <- rownames(mu.v)
	if(!is.null(drop_fate))lineage_list <- lineage_list[-drop_fate]
	}else{
	writeLines("Allow shared cell state between different lineage...")
	label_list <- list()
	for(i in 1:nrow(mu.v)){
	  label_list[[i]] <- colnames(mu.v)[which(mu.v[i,]>cut_off)]
	}
	uncertain_cellstate <- colnames(mu.v)[colnames(mu.v) %in% unique(unlist(label_list)) == FALSE]
	for(i in 1:nrow(mu.v)) label_list[[i]] <- c(label_list[[i]],uncertain_cellstate)

	lineage_list <- list()
	drop_fate <- NULL
	for(i in 1:nrow(mu.v)){
	  lineage_list[[i]] <- label_list[[i]]
	  lineage_list[[i]] <- rownames(fate_prob)[which(class %in% lineage_list[[i]])]
	  if(length(lineage_list[[i]])==0) drop_fate <- c(drop_fate,i)
	}
	names(lineage_list) <- rownames(mu.v)
	if(!is.null(drop_fate))lineage_list <- lineage_list[-drop_fate]
	}
	lineage_list
}

Sketching <- function(exp.m,varID_obj,var,n_cell,sketch.method,ndim){
  pca <- t(varID_obj$dimRed)
  #pca <- t(apply(pca,1,function(x){x/norm(x,"2")}))
  sample_m <- NULL
  if(sketch.method == "SeuratSketching"){
    object <- CreateSeuratObject(exp.m)
    object <- NormalizeData(object)
    object <- FindVariableFeatures(object)
  }
  if(sketch.method == "geosketch"){
    if(!is.null(ndim)){
      geneID <- rownames(exp.m)
      sampleID <- colnames(exp.m)
      #exp.m <- exp.m %*% diag(10^6/colSums(exp.m))
      rownames(exp.m) <- geneID
      colnames(exp.m) <- sampleID
    }
    if(var){X = t(log(exp.m[varID_obj$B$genes,]+1))}else{
      X = t(log(exp.m[rownames(varID_obj$regData$pearsonRes),]+1))}
    geosketch <- import('geosketch')
    s <- rsvd(X, k=ndim)
    pca <- s$u %*% diag(s$d)
  }

  if(sketch.method == "geosketch"){
    X.pcs <- pca
    sketch.indices <- geosketch$gs(X.pcs, as.integer(n_cell), one_indexed = TRUE)
  }
  if(sketch.method == "SeuratSketching"){
    atoms <- LeverageScoreSampling(object = object, num.cells = n_cell)
    sketch.indices <- which(colnames(object) %in% colnames(atoms))
  }
  if(sketch.method == "random"){
    sketch.indices <- sample(1:ncol(exp.m),n_cell,replace=FALSE)
  }
  sketch.indices <- unlist(sketch.indices)
  sketch.indices
}


ExplaineVariance <- function(mat,refMat){
  var <- NULL
  for(i in 1:ncol(refMat)){
    data <- cbind(refMat[,i],mat)
    colnames(data) <- c("y",colnames(mat))
    data <- as.data.frame(data)
    lm <- lm(y~., data)
    var <- c(var, cor(lm$fitted.value, refMat[,i])^2)
  }
  mean(var)
}

Manifold_Ratio <- function(NN,sketch.indices){
  nn_set <- as.integer(as.numeric(NN[,sketch.indices]))
  nn_set <- unique(nn_set)
  length(nn_set) / ncol(NN)
}

SampleScore <- function(exp.m,TF,varID_obj,gep_list){
  refMat <- rARPACK::svds(exp.m[TF,],10)$u
  rownames(refMat) <- TF
  pca <- t(varID_obj$dimRed)
  score <- score2 <- score3 <- NULL
  for(i in 1:length(gep_list)){
    sketch.indices <- which(colnames(exp.m) %in% colnames(gep_list[[i]]))
    score <- c(score,ExplaineVariance(exp.m[TF,sketch.indices],refMat[TF,]))
    score2 <- c(score2, hausdorff_dist(pca[sketch.indices,],pca[-sketch.indices,]))
    score3 <- c(score3, Manifold_Ratio(varID_obj$NN,sketch.indices))
  }
  score <- rankScore2(score)
  score2 <- rankScore2(-score2)
  score3 <- rankScore2(score3)
  score+score2+score3
}

rankScore2 <- function(score){
  #score <- abs(score)
  score <- (1/(rank(-score))^2)
  score
}
